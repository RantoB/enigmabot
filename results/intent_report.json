{
  "ask_for_riddle": {
    "precision": 1.0,
    "recall": 0.75,
    "f1-score": 0.8571428571428571,
    "support": 4,
    "confused_with": {
      "inform_kind_of_riddle": 1
    }
  },
  "inform_name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 22,
    "confused_with": {}
  },
  "societe_mysterieuse": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "question_pitch": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 13,
    "confused_with": {}
  },
  "deny": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 14,
    "confused_with": {}
  },
  "bot_challenge": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "meurtre_krutenau": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "out_of_scope": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 24,
    "confused_with": {}
  },
  "faq": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 237,
    "confused_with": {}
  },
  "affirm": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 17,
    "confused_with": {}
  },
  "thanks": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "answer_the_riddle": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 12,
    "confused_with": {}
  },
  "inform_kind_of_riddle": {
    "precision": 0.9473684210526315,
    "recall": 1.0,
    "f1-score": 0.972972972972973,
    "support": 18,
    "confused_with": {}
  },
  "greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "accuracy": 0.9974811083123426,
  "macro avg": {
    "precision": 0.9964912280701754,
    "recall": 0.9833333333333333,
    "f1-score": 0.9886743886743887,
    "support": 397
  },
  "weighted avg": {
    "precision": 0.9976136815590613,
    "recall": 0.9974811083123426,
    "f1-score": 0.9973352265543702,
    "support": 397
  }
}